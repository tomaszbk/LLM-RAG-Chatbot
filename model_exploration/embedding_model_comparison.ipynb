{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8234e-02, -3.3270e-02,  1.1110e-01,  8.0928e-02, -6.7070e-02,\n",
      "        -7.7351e-02,  5.9226e-02, -7.6657e-02,  2.0832e-02,  5.0144e-02,\n",
      "         2.3562e-02, -2.9504e-02,  2.1711e-02,  2.7174e-02,  5.5318e-02,\n",
      "        -4.8389e-03,  1.1614e-02, -2.1740e-02, -4.6921e-02, -4.5097e-02,\n",
      "        -5.8431e-02,  4.9420e-02,  1.0028e-02,  4.4050e-03, -1.1355e-01,\n",
      "        -1.7065e-02,  6.5421e-02, -1.7996e-02,  3.6328e-02, -2.1533e-02,\n",
      "        -5.8041e-02,  9.9074e-03,  5.0377e-02,  1.3503e-02, -3.7831e-03,\n",
      "        -7.2319e-03,  1.5691e-03, -2.5259e-02,  3.2062e-02,  5.8019e-02,\n",
      "        -7.5156e-03, -7.5619e-03,  1.6762e-02, -5.2282e-02, -3.4996e-02,\n",
      "        -2.2992e-02, -5.4908e-02, -3.4377e-02,  1.6029e-02, -6.5723e-04,\n",
      "        -9.3028e-02,  2.1957e-02, -1.2922e-02,  2.3898e-02,  1.6532e-03,\n",
      "        -6.4742e-03, -1.7111e-02,  3.9563e-03,  5.0674e-02, -7.2320e-03,\n",
      "        -1.1371e-02,  1.0544e-01,  2.9574e-02, -1.1621e-02,  4.2336e-02,\n",
      "        -8.1642e-02, -3.3025e-02, -3.4053e-03, -6.0422e-02, -3.2401e-03,\n",
      "         5.3772e-02,  6.3565e-02,  7.3710e-03,  3.0829e-02, -3.5176e-02,\n",
      "        -2.5573e-02,  5.4558e-02,  3.2835e-02,  7.7864e-02, -7.0851e-03,\n",
      "        -2.9771e-02, -1.0483e-01, -2.6762e-02,  2.5499e-02,  3.0414e-02,\n",
      "        -1.3401e-02, -2.0943e-02, -4.3620e-02, -1.1652e-01,  8.2924e-03,\n",
      "        -2.8181e-02, -5.3554e-03, -2.3864e-02, -2.8234e-02, -7.6440e-02,\n",
      "        -3.5657e-02,  8.0777e-03, -9.2710e-02, -6.4291e-02,  6.6405e-02,\n",
      "         2.8908e-02,  5.5515e-02,  2.7841e-02,  7.3490e-02,  6.2488e-02,\n",
      "         3.8345e-02, -7.6469e-02,  3.1996e-02, -1.1435e-02, -3.0706e-02,\n",
      "         1.5836e-02, -5.2346e-02,  6.7030e-03,  7.1019e-03,  8.3189e-02,\n",
      "        -1.5026e-02, -9.6771e-02, -1.9599e-02,  6.0117e-02, -3.6486e-02,\n",
      "         4.5829e-02,  1.2737e-03, -4.5235e-02,  7.5911e-03, -6.1595e-03,\n",
      "        -1.8538e-02, -5.7294e-03, -4.7783e-33,  4.9678e-02,  3.3037e-02,\n",
      "        -1.5472e-02,  6.7803e-02,  8.6821e-03, -1.0381e-02, -4.4991e-02,\n",
      "        -5.4444e-02, -5.2441e-02, -8.2654e-02,  7.5724e-03,  1.7785e-02,\n",
      "        -3.3466e-02,  1.5400e-02, -5.7041e-02,  3.4006e-02, -2.1856e-02,\n",
      "         1.7826e-02,  8.2353e-02,  9.7150e-02, -2.1312e-02, -6.7841e-02,\n",
      "         4.2437e-02,  5.2255e-02,  4.6894e-02, -3.9348e-02,  1.7180e-02,\n",
      "        -1.3650e-01, -5.6980e-02,  1.0310e-02,  5.2655e-02,  3.1571e-02,\n",
      "         7.0040e-02,  2.1390e-02, -9.1157e-02, -1.1387e-01, -2.1534e-02,\n",
      "        -7.1731e-02, -7.2729e-02,  8.7997e-02,  1.0401e-01, -1.1009e-02,\n",
      "         3.7713e-02, -1.0879e-02, -8.2449e-02, -1.4274e-02, -3.6215e-02,\n",
      "         4.2103e-02, -2.6899e-02, -8.4611e-03,  2.4154e-02,  2.7071e-02,\n",
      "         5.6531e-03, -2.2011e-02, -2.8572e-02, -8.9893e-03, -9.8661e-03,\n",
      "        -1.0855e-02,  1.5036e-02,  1.0644e-01,  1.3177e-02,  2.9385e-02,\n",
      "         5.4730e-02, -3.4838e-02,  2.5775e-02, -1.2955e-01, -3.3989e-02,\n",
      "         1.2142e-02,  1.7695e-02, -4.2287e-03, -1.6938e-02,  1.4638e-02,\n",
      "         3.5428e-02,  8.2859e-03,  2.3152e-02,  5.7640e-03,  7.5517e-02,\n",
      "         3.1249e-03,  7.8255e-02, -8.3871e-02,  4.6736e-02,  6.5003e-02,\n",
      "        -1.7864e-02,  3.7629e-02, -5.0766e-03,  1.9098e-02, -3.5624e-02,\n",
      "        -3.0055e-02, -4.4813e-02,  2.8667e-02, -3.2730e-02,  2.6322e-03,\n",
      "         8.1242e-02, -5.5702e-02, -3.8070e-02,  1.9778e-33,  7.4433e-02,\n",
      "         8.3186e-02, -4.3013e-02, -8.9878e-02, -1.2202e-01,  3.3977e-02,\n",
      "        -2.6551e-02,  1.3664e-01, -5.3404e-02,  1.1095e-01,  1.5534e-02,\n",
      "         3.4004e-02,  1.7323e-02, -6.7486e-02,  5.9029e-02, -1.8076e-02,\n",
      "         5.9491e-02,  1.8966e-02, -1.4515e-03, -3.5881e-02, -1.1327e-01,\n",
      "         7.0395e-02,  8.2644e-03,  1.1593e-02, -5.5291e-02, -1.9815e-02,\n",
      "         1.0810e-02,  1.6486e-02,  3.2348e-02, -4.6429e-02,  3.4241e-02,\n",
      "        -5.1047e-02, -4.9707e-02,  2.3289e-03,  2.8197e-02,  3.7772e-02,\n",
      "        -6.0038e-02, -1.1775e-01, -1.4594e-03,  3.8326e-02, -1.3851e-02,\n",
      "        -1.7415e-03,  3.8380e-02,  7.5886e-02,  6.8195e-02, -2.4545e-02,\n",
      "         3.5181e-03, -5.0260e-02,  1.0862e-02,  4.7973e-02, -7.9203e-02,\n",
      "        -2.6140e-02,  2.8217e-02, -2.6699e-02,  2.4320e-03, -7.3549e-03,\n",
      "         2.9462e-02,  3.8304e-02,  5.4001e-02, -2.9242e-02, -1.5658e-02,\n",
      "         6.1388e-02,  3.9415e-02,  1.3148e-01, -4.6845e-02, -4.4726e-02,\n",
      "        -2.8861e-02, -2.4578e-02,  3.2628e-02, -1.2963e-01, -1.9090e-02,\n",
      "        -5.0964e-03, -2.5849e-02, -5.0448e-02,  2.3557e-02,  1.2510e-02,\n",
      "         5.6963e-02, -7.4147e-03,  2.0452e-02,  1.1889e-02, -2.3357e-02,\n",
      "        -6.8497e-03, -4.4779e-02, -1.9509e-02,  1.2655e-02, -2.5347e-02,\n",
      "        -1.2567e-02,  5.3354e-02,  3.3322e-02, -4.5514e-02, -4.8372e-02,\n",
      "         8.1317e-02,  9.9568e-03,  8.1301e-03, -3.5865e-02, -1.7740e-08,\n",
      "        -4.4879e-02, -6.7613e-03, -3.8964e-02,  3.5052e-02,  1.0686e-02,\n",
      "         3.3140e-02, -7.0083e-02, -7.9370e-02, -9.4737e-02,  2.1222e-02,\n",
      "         1.1038e-01,  1.1967e-02, -1.2327e-01,  5.6997e-03,  5.5119e-02,\n",
      "         1.3671e-02,  2.2398e-02,  4.6101e-02,  5.5194e-02,  3.8048e-03,\n",
      "        -6.7843e-02,  6.5207e-02,  1.4802e-02, -1.4846e-02, -6.8451e-03,\n",
      "        -8.9211e-02,  5.3694e-04,  2.7217e-02, -8.6027e-02,  2.4810e-02,\n",
      "        -4.9269e-02,  1.4646e-01,  5.9160e-03,  1.7521e-02,  4.1678e-02,\n",
      "        -9.7336e-02,  8.7781e-02, -2.6403e-02,  9.8381e-02, -6.3098e-02,\n",
      "         5.1549e-03,  1.0227e-01, -3.6566e-02, -8.3533e-02,  1.2289e-02,\n",
      "         6.9807e-02,  1.0694e-01, -1.0648e-01, -9.4188e-03, -7.6564e-03,\n",
      "        -1.4288e-01, -1.3744e-02,  1.3712e-02,  2.9412e-02,  2.0953e-02,\n",
      "         4.5924e-02, -4.7375e-02, -3.1004e-02,  5.5354e-02,  7.8458e-02,\n",
      "         4.8881e-02,  1.0524e-01,  1.7490e-02,  1.2082e-02], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").cuda()\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sentence_embedding(sentence: str):\n",
    "    encoded_input = tokenizer(sentence, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "    sentence_embeddings = sentence_embeddings.flatten()\n",
    "    return F.normalize(sentence_embeddings, p=2, dim=0)\n",
    "\n",
    "emb1= get_sentence_embedding(\"Hello, my dog is cute\")\n",
    "print(emb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "text = \"Hello, my dog is cute\"\n",
    "\n",
    "text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "print(text_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(384, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((emb1==text_embedding).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: method 1 is faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
