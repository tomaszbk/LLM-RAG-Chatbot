{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['A hamburger costs 10 dollars', 'A hotdog costs 5 dollars', 'A pizza costs 15 dollars', 'A taco costs 2 dollars', 'A soda costs 1 dollar', \"we don't sell coke\"]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_sentences_embeddings(sentences: list):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    return F.normalize(sentence_embeddings, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "def insert_embeddings(embeddings_dict: dict):\n",
    "    engine = create_engine('postgresql://postgres:postgres@localhost:5432/vector_db')\n",
    "\n",
    "\n",
    "    with Session(engine) as session:\n",
    "        for _, value in embeddings_dict.items():\n",
    "            query = text(\"\"\"\n",
    "                INSERT INTO business_embeddings (embedding, content) VALUES\n",
    "                (:vector, :content)\n",
    "            \"\"\")\n",
    "            session.execute(query, dict(vector=value['embedding'], content=value['content']))\n",
    "\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_embeddings_to_str(embeddings: torch.Tensor):\n",
    "    new_list = []\n",
    "    for embedding in embeddings:\n",
    "        new_list.append(str([x.item() for x in list(embedding)]))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {idx: {'embedding': embedding, 'content': content} for idx, (embedding, content) in enumerate(zip(transform_embeddings_to_str(get_sentences_embeddings(sentences)), sentences))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.04257448762655258, 0.0365988090634346, -0.0030170485842972994, -0.028192119672894478, 0.013431346043944359, 0.0034944803919643164, 0.0211520716547966, 0.08243482559919357, 0.04188685864210129, 0.06088932231068611, 0.045378293842077255, -0.04801978915929794, -0.023994581773877144, 0.003970183897763491, -0.04590587317943573, -0.11710409075021744, 0.08210884779691696, -0.0015061248559504747, -0.012893849052488804, -0.012492349371314049, -0.021876046434044838, -0.03169425576925278, -0.05823637917637825, 0.04573022201657295, 0.045724429190158844, -0.07080163806676865, 0.05294065177440643, -0.08163420110940933, -0.05111908167600632, 0.004920905455946922, -0.022669702768325806, -0.07914390414953232, -0.08523766696453094, 0.05273035541176796, -0.0005112505168654025, -0.11234196275472641, 0.08515442907810211, 0.016209090128540993, -0.09812614321708679, 0.02992318384349346, 0.011334304697811604, -0.0033304214011877775, 0.01637197472155094, -0.08399442583322525, 0.0514669194817543, -0.016521822661161423, -0.12039043009281158, 0.08816380053758621, 0.01755288615822792, 0.019261827692389488, -0.004437064751982689, -0.017882801592350006, -0.058514486998319626, -0.07270970195531845, 0.10078541189432144, 0.03289375826716423, 0.030202893540263176, -0.03492220118641853, 0.031509529799222946, 0.11545684188604355, -0.08438898622989655, -0.007895802147686481, -0.056098584085702896, 0.012825299985706806, 0.042763326317071915, -0.06973806768655777, -0.04269246757030487, -0.022055910900235176, -0.12084704637527466, 0.09445768594741821, 0.06878035515546799, -0.03313000127673149, 0.07536213099956512, -0.05517755076289177, -0.01619177870452404, -0.02522987313568592, 0.12024295330047607, 0.0009993978310376406, 0.016609525308012962, 0.04315260052680969, 0.0030453591607511044, -0.020566584542393684, -0.0609552338719368, -0.06860870867967606, -0.02745579555630684, -0.028952011838555336, 0.02100660465657711, -0.04678643122315407, 0.034816086292266846, -0.009049122221767902, 0.043124254792928696, -0.031635165214538574, -0.03254400193691254, -0.06129360944032669, -0.0638037696480751, -0.0240160059183836, 0.024325229227542877, 0.042197540402412415, -0.0055137621238827705, 0.04013427719473839, -0.006333792582154274, 0.031713973730802536, 0.11621906608343124, -0.018436327576637268, 0.01493008341640234, 0.005579362157732248, 0.02980870194733143, 0.05213752016425133, 0.0717279240489006, 0.026366403326392174, 0.013657497242093086, 0.047713540494441986, -0.06931982934474945, -0.058630332350730896, -0.002490545157343149, -0.052450232207775116, 0.07214827835559845, -0.15742100775241852, 0.0010683867149055004, -0.035787858068943024, -0.04722961038351059, 0.02605922892689705, 0.04963286966085434, 0.03145042806863785, -0.12314079701900482, -0.01023639552295208, 0.019461380317807198, -4.0680321978647365e-33, -0.05802116543054581, -0.015527035109698772, -0.02478010021150112, -0.05496994033455849, 0.01266813836991787, -0.0054521686397492886, 0.006611816585063934, 0.07407196611166, -0.01179256197065115, 0.029058784246444702, -0.006776743568480015, -0.024137945845723152, -0.06797102093696594, 0.0667092576622963, 0.06470411270856857, -0.016663428395986557, -0.017948156222701073, 0.023909900337457657, 0.010996192693710327, -0.04546390101313591, -0.08124682307243347, -0.030932143330574036, 0.0437842458486557, -0.020084761083126068, -0.024958815425634384, -0.01590825244784355, -0.031746987253427505, -0.025811728090047836, 0.003397284308448434, -0.02341412380337715, 0.034484975039958954, 0.08459287136793137, 0.03863101825118065, -0.06172756105661392, 0.03322458639740944, -0.018079029396176338, 0.14529365301132202, 0.004075627774000168, 0.05922400578856468, -0.08565770089626312, -0.02526005357503891, -0.02150830440223217, -0.03581925481557846, -0.0019460079493001103, 0.03512345626950264, -0.0008221732568927109, 0.10578528791666031, 0.0013278097612783313, -0.052568018436431885, -0.0888814851641655, -0.024479495361447334, 0.014412048272788525, 0.0008795649628154933, 0.06935272365808487, -0.055228717625141144, 0.009152398444712162, 0.0897984579205513, -0.05164925009012222, 0.06746134907007217, 0.02492677792906761, 0.019620342180132866, 0.031767137348651886, 0.013596312142908573, -0.006905444897711277, -0.02633320353925228, 0.03198890760540962, 0.061516471207141876, 0.028397642076015472, 0.10102982074022293, 0.0327417254447937, 0.033138394355773926, -0.03888411074876785, 0.1006767600774765, -0.06980255246162415, 0.08414139598608017, 0.050436098128557205, 0.01692654937505722, 0.023267662152647972, 0.0025632523465901613, 0.020638685673475266, 0.06671509891748428, 0.02219976671040058, -0.0004976753261871636, 0.0751880407333374, 0.06439919024705887, 0.014959367923438549, 0.028722496703267097, -0.041600581258535385, -0.029887806624174118, 0.03050766885280609, 0.030370470136404037, 0.036215946078300476, 0.04329518601298332, -0.06379977613687515, 0.06802041083574295, 1.3922286931490392e-33, 0.008453838527202606, -0.0007253620424307883, 0.0029093525372445583, 0.03476424887776375, 0.014263437129557133, -0.06243304908275604, -0.02437930554151535, 0.01848127879202366, -0.04898210987448692, -0.029506899416446686, -0.09915310889482498, 0.04551023989915848, -0.026653531938791275, -0.016376547515392303, 0.07438500225543976, 0.04437478631734848, -0.06715255230665207, 0.06287678331136703, 0.02948453463613987, -0.04020638391375542, -0.004836992360651493, 0.014127233996987343, 0.017519330605864525, 0.04224754124879837, -0.014440136030316353, 0.02772243320941925, -0.02099168486893177, 0.032664425671100616, -0.03523068502545357, -0.04720008000731468, -0.10008694231510162, -0.019997937604784966, 0.02528364770114422, 0.00466659851372242, -0.1011648178100586, 0.007292882539331913, 0.012436416931450367, 0.038124680519104004, 0.018215220421552658, -0.028411444276571274, 0.017588743939995766, 0.01684681884944439, -0.005035154055804014, 0.02907118760049343, 0.019241996109485626, -0.027163662016391754, -0.008382144384086132, -0.04798818379640579, 0.010352837853133678, 0.03440074995160103, 0.07594013214111328, -0.05611686035990715, 0.0247162114828825, -0.0014135435922071338, -0.13060729205608368, 0.013682282529771328, 0.01464729756116867, -0.00041917344788089395, 0.04568343237042427, 0.01816209964454174, -0.02701421082019806, 0.057739559561014175, -0.049460962414741516, 0.0013602334074676037, 0.055814385414123535, 0.041643183678388596, 0.04610308259725571, -0.025484399870038033, 0.01009630598127842, -0.0609169527888298, -0.03901507705450058, 0.03945533186197281, 0.07775610685348511, -0.03795284777879715, -0.03289046138525009, 0.040337059646844864, 0.04931612312793732, 0.02730550430715084, 0.07407637685537338, 0.010819605551660061, 0.025678059086203575, -0.0747302994132042, 0.024104414507746696, -0.0266098715364933, 0.005398462992161512, -0.03955472260713577, 0.017982125282287598, 0.034383174031972885, -0.06714951992034912, 0.12542861700057983, -0.07453611493110657, 0.07286196947097778, 0.04852242022752762, -0.06188745051622391, -0.015326796099543571, -1.450933151403433e-08, -0.0009202068322338164, -0.006833339110016823, 0.020895779132843018, 0.007987710647284985, 0.04366491734981537, -0.06514260172843933, 0.012952085584402084, 0.001867832732386887, 0.016823459416627884, 0.06215371564030647, -0.03929198160767555, 0.0048099118284881115, -0.10080254822969437, 0.10473016649484634, -0.1596514880657196, -0.020755495876073837, 0.02879796177148819, -0.010393815115094185, -0.0018709097057580948, 0.03920573741197586, -0.06637907028198242, 0.15159058570861816, -0.04011646658182144, -0.015024884603917599, 0.013223768211901188, 0.01860339380800724, -0.021775372326374054, 0.10187438875436783, 0.021322237327694893, 0.02911282144486904, -0.027934348210692406, 0.018116889521479607, -0.07929114252328873, 0.006151158362627029, 0.046842239797115326, 0.005423407070338726, -0.10220813006162643, -0.05202901363372803, -0.02488713525235653, -0.11214430630207062, -0.03757528215646744, -0.01943817175924778, -0.04595515877008438, -0.014628397300839424, -0.027875561267137527, 0.004162729252129793, -0.11319389194250107, 0.016048084944486618, -0.015775883570313454, 0.06826261430978775, -0.018762920051813126, 0.056051675230264664, -0.052351322025060654, -0.0687471479177475, -0.05026707053184509, -0.07627417147159576, 0.06768323481082916, -0.027200788259506226, 0.03313349932432175, 0.05028801038861275, 0.025495050475001335, -0.06496219336986542, -0.001622838550247252, 0.009102915413677692]'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str([x.item() for x in list(embeddings_dict[0]['embedding'])])\n",
    "embeddings_dict[0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_embeddings(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_embeddings(p_embedding: torch.Tensor):\n",
    "    engine = create_engine('postgresql://postgres:postgres@localhost:5432/vector_db')\n",
    "    p_embedding = transform_embeddings_to_str(p_embedding)[0]\n",
    "    with Session(engine) as session:\n",
    "        query = text(\"\"\"\n",
    "            SELECT * FROM business_embeddings ORDER BY :p_embedding <-> embedding LIMIT 2;\n",
    "        \"\"\")\n",
    "        result = session.execute(query, dict(p_embedding= p_embedding)).fetchall()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'how much does a burger cost?'\n",
    "result_embeddings = retrieve_embeddings(get_sentences_embeddings([prompt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A hamburger costs 10 dollars'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_embeddings[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "t = torch.tensor(   [  [2.0, 5],\n",
    "                        [35.0, 5],\n",
    "                        [440, 5],\n",
    "                        [-5, 4]  ], dtype=torch.float32)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.,   5.],\n",
       "        [ 35.,   5.],\n",
       "        [440.,   5.],\n",
       "        [ -5.,   4.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071, 0.7071],\n",
       "        [0.7071, 0.7071]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.normalize(torch.Tensor([[1, 1],\n",
    "                          [1,1]]), dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
